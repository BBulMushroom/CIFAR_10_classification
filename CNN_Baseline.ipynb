{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN_Baseline.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BBulMushroom/CIFAR_10_classification/blob/ResNet9/CNN_Baseline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wiTQibprRnlj"
      },
      "source": [
        "# **Cifar10 image classification**\n",
        "******************************************\n",
        "**점수관련**  \n",
        "본 프로젝트는 Accuracy 점수와 보고서를 성적에 반영할 예정입니다. 평가 항목은 아래와 같습니다. \n",
        "\n",
        "A. 결과 (40%)\n",
        "- Metric 성능 :(이미지 분류 - Accuracy)\n",
        "\n",
        "B. 신규성 (30%)\n",
        "- Network 변경 내용 - **필수**\n",
        "- 성능 개선 및 overfitting 방지 시도 (ex. train validation split)\n",
        "\n",
        "C. 이론적 근거 (20%)\n",
        "- 기존 baseline과의 차별점 \n",
        "- 성능 개선을 위한 시도와 이유\n",
        "\n",
        "D. 보고서 완성도 (10%)\n",
        "\n",
        "******************************************\n",
        "**보고서**\n",
        "1. 연구 목적\n",
        "2. 모델 구조\n",
        "3. 실험 내용\n",
        "4. 실험 결과\n",
        "5. 고찰 및 결론\n",
        "6. Colab 파일 (동작 가능여부)\n",
        "\n",
        "제출하실 파일은 **주피터 노트북 파일**('.ipynb',파일>다운로드)과 **결과 보고서**(pdf)입니다.\n",
        "******************************************\n",
        "**코드 검증**  \n",
        "- 코드 성능 평가(metric)는 torchvision.datasets에 있는 cifar10의 testset을 사용해 Accuracy로 평가합니다.\n",
        "- pretrain 모델 사용 불가능합니다.\n",
        "\n",
        "또한 Random 라이브러리 사용시에 seed 고정하는 등 재현을 고려하시고 코딩부탁드립니다. \n",
        "******************************************\n",
        "**GPU 사용 법**  \n",
        "런타임 > 런타임 유형 변경 > 하드웨어 가속기에서 GPU를 선택하면 GPU를 사용 할 수 있습니다.  \n",
        "******************************************\n",
        "**Colab 사용시 유의사항**  \n",
        "12시간 단위로 가상머신을 사용할 수 있고 12시간이 지나면 모든 파일과 작업로그들이 초기화 됩니다. 또한, 12시간 넘게 GPU를 사용하기는 어려우니 일찍 시작하셔서 틈틈히 실험해보시는 것을 추천드립니다.\n",
        "\n",
        "\n",
        "******************************************\n",
        "**Q?**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zZfJXOcNxcAK",
        "outputId": "7e8eb783-c96e-4552-95ff-972c0c966522"
      },
      "source": [
        "# Training\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from google.colab import drive\n",
        "import time\n",
        "\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "# 하이퍼 파라미터\n",
        "EPOCH = 20\n",
        "batch_size = 400\n",
        "learning_rate = 1e-3\n",
        "grad_clip = 0.1\n",
        "weight_decay = 1e-4\n",
        "\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print(f'{device} is available')\n",
        "\n",
        "# 분류 Class list\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "\n",
        "# 이미지 전처리\n",
        "torch.manual_seed(500)  # 시드 고정\n",
        "train_transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.RandomCrop(32, padding=4, padding_mode = 'reflect'),\n",
        "     transforms.RandomHorizontalFlip(),\n",
        "     transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010), inplace=True)]\n",
        "    )\n",
        "test_transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))]\n",
        "    )\n",
        "\n",
        "# Dataset. 변경 불가\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=train_transform)\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=test_transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size*2)\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "cuda:0 is available\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "23oA0g2axgcP"
      },
      "source": [
        "# Baseline CNN Network\n",
        "\n",
        "def conv_block(in_channels, out_channels, pool=False):\n",
        "  layers = [nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1), \n",
        "            nn.BatchNorm2d(out_channels), \n",
        "            nn.ReLU(inplace=True)]\n",
        "  if pool: layers.append(nn.MaxPool2d(2))\n",
        "  return nn.Sequential(*layers)\n",
        "\n",
        "class ResNet9(nn.Module):\n",
        "  def __init__(self, in_channels, num_classes):\n",
        "    super().__init__()\n",
        "        \n",
        "    self.conv1 = conv_block(in_channels, 64)\n",
        "    self.conv2 = conv_block(64, 128, pool=True)\n",
        "    self.res1 = nn.Sequential(conv_block(128, 128), conv_block(128, 128))\n",
        "    \n",
        "    self.conv3 = conv_block(128, 256, pool=True)\n",
        "    self.conv4 = conv_block(256, 512, pool=True)\n",
        "    self.res2 = nn.Sequential(conv_block(512, 512), conv_block(512, 512))\n",
        "    \n",
        "    self.classifier = nn.Sequential(nn.MaxPool2d(4), \n",
        "                                        nn.Flatten(), \n",
        "                                        nn.Linear(512, num_classes))\n",
        "        \n",
        "  def forward(self, xb):\n",
        "    out = self.conv1(xb)\n",
        "    out = self.conv2(out)\n",
        "    out = self.res1(out) + out\n",
        "    out = self.conv3(out)\n",
        "    out = self.conv4(out)\n",
        "    out = self.res2(out) + out\n",
        "    out = self.classifier(out)\n",
        "    return out\n",
        "\n",
        "\n",
        "# Network 선언\n",
        "net = ResNet9(3, 10).to(device)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NtweS09sMWoh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "824c8521-c569-48ae-c909-af4e1a819a23"
      },
      "source": [
        "# criterion. 변경 '가능'\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Optimizer\n",
        "optimizer = optim.Adam(net.parameters(), lr=learning_rate, weight_decay=weight_decay, amsgrad=True)\n",
        "\n",
        "# Scheduler\n",
        "scheduler = optim.lr_scheduler.OneCycleLR(optimizer=optimizer, max_lr = learning_rate, epochs=EPOCH, steps_per_epoch=len(trainloader))\n",
        "\n",
        "loss_ = []\n",
        "n = len(trainloader)\n",
        "\n",
        "# Training\n",
        "for epoch in range(EPOCH): \n",
        "\n",
        "  running_loss = 0.0\n",
        "  start = time.time()\n",
        "  for i, data in tqdm(enumerate(trainloader, 0)):\n",
        "    \n",
        "    inputs, labels = data[0].to(device), data[1].to(device) # 배치 데이터\n",
        "\n",
        "    outputs = net(inputs)\n",
        "    loss = criterion(outputs, labels) # 크로스 엔트로피 손실함수 계산 \n",
        "\n",
        "    loss.backward() # backpropagation\n",
        "    nn.utils.clip_grad_value_(net.parameters(), grad_clip)  # Gradiant clipping\n",
        "\n",
        "    optimizer.step() # 가중치 최적화\n",
        "    optimizer.zero_grad() # 배치마다 optimizer 초기화\n",
        "\n",
        "    running_loss += loss.item()\n",
        "    scheduler.step()\n",
        "  \n",
        "  torch.save(net.state_dict() ,'/content/gdrive/Shareddrives/전자공학종합설계/ResNet//model_ckpt.pt') # 모델 저장, path 수정\n",
        "  loss_.append(running_loss / n)\n",
        "  print('[%d] loss: %.3f' %(epoch + 1, running_loss / len(trainloader)))\n",
        "  print(\"epoch time :\", time.time()-start)\n",
        "\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  correct_pred = {classname: 0 for classname in classes}\n",
        "  total_pred = {classname: 0 for classname in classes}\n",
        "  # since we're not training, we don't need to calculate the gradients for our outputs\n",
        "  with torch.no_grad():\n",
        "      for data in testloader:\n",
        "          images, labels = data[0].to(device), data[1].to(device)\n",
        "          # calculate outputs by running images through the network\n",
        "          outputs = net(images)\n",
        "          # the class with the highest energy is what we choose as prediction\n",
        "          _, predicted = torch.max(outputs.data, 1)\n",
        "          total += labels.size(0)\n",
        "          correct += (predicted == labels).sum().item()\n",
        "          # collect the correct predictions for each class\n",
        "          for label, prediction in zip(labels, predicted):\n",
        "              if label == prediction:\n",
        "                  correct_pred[classes[label]] += 1\n",
        "              total_pred[classes[label]] += 1\n",
        "\n",
        "  print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
        "      100 * correct / total))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "125it [01:20,  1.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1] loss: 1.477\n",
            "epoch time : 80.94216179847717\n",
            "Accuracy of the network on the 10000 test images: 60 %\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "9it [00:05,  1.53it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sf9UIvloTtt2"
      },
      "source": [
        "# Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "amoq6d5NMYvA"
      },
      "source": [
        "# Evaluation\n",
        "\n",
        "# 수정\n",
        "net = ResNet9(3, 10)\n",
        "net.to(device)\n",
        "net.load_state_dict(torch.load('/content/gdrive/Shareddrives/전자공학종합설계/ResNet//model_ckpt.pt')) # 저장된 모델 불러오기\n",
        "\n",
        "\n",
        "# 이하 전체 수정 불가\n",
        "correct = 0\n",
        "total = 0\n",
        "correct_pred = {classname: 0 for classname in classes}\n",
        "total_pred = {classname: 0 for classname in classes}\n",
        "# since we're not training, we don't need to calculate the gradients for our outputs\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data[0].to(device), data[1].to(device)\n",
        "        # calculate outputs by running images through the network\n",
        "        outputs = net(images)\n",
        "        # the class with the highest energy is what we choose as prediction\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "        # collect the correct predictions for each class\n",
        "        for label, prediction in zip(labels, predicted):\n",
        "            if label == prediction:\n",
        "                correct_pred[classes[label]] += 1\n",
        "            total_pred[classes[label]] += 1\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
        "    100 * correct / total))\n",
        "\n",
        "# print accuracy for each class\n",
        "for classname, correct_count in correct_pred.items():\n",
        "    accuracy = 100 * float(correct_count) / total_pred[classname]\n",
        "    print(\"Accuracy for class {:5s} is: {:.1f} %\".format(classname,\n",
        "                                                   accuracy))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1lUnuy-g4Aiq"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def imshow(img):\n",
        "    img = img / 2 + 0.5     # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.figure(figsize=(20,10))\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "dataiter = iter(testloader)\n",
        "images, labels = dataiter.next()\n",
        "\n",
        "# print images\n",
        "imshow(torchvision.utils.make_grid(images))\n",
        "print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(8)))\n",
        "\n",
        "net = Net()\n",
        "net.to(device)\n",
        "net.load_state_dict(torch.load('/content/gdrive/Shareddrives/전자공학종합설계/ResNet//model_ckpt.pt'))\n",
        "\n",
        "_, predicted = torch.max(outputs, 1)\n",
        "\n",
        "print('Predicted: ', ' '.join('%5s' % classes[predicted[j]]\n",
        "                              for j in range(8)))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}